# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['inseq',
 'inseq.attr',
 'inseq.attr.feat',
 'inseq.attr.feat.ops',
 'inseq.commands',
 'inseq.data',
 'inseq.models',
 'inseq.utils']

package_data = \
{'': ['*']}

install_requires = \
['captum>=0.6.0,<0.7.0',
 'matplotlib>=3.5.3,<3.6.0',
 'numpy>=1.21.6,<2.0.0',
 'poethepoet>=0.13.1,<0.14.0',
 'protobuf>=3.20.1,<4.0.0',
 'rich>=10.13.0,<11.0.0',
 'scipy>=1.8.1,<2.0.0',
 'torch>=1.13.1,<2.0.0',
 'torchtyping>=0.1.4,<0.2.0',
 'tqdm>=4.64.0,<5.0.0',
 'transformers[sentencepiece,tokenizers,torch]>=4.22.0,<5.0.0']

extras_require = \
{'datasets': ['datasets[datasets]>=2.3.2,<3.0.0'],
 'notebook': ['ipykernel[notebook]>=6.19.2,<7.0.0',
              'ipywidgets[notebook]>=8.0.0rc2,<9.0.0'],
 'sklearn': ['joblib[sklearn]>=1.2.0,<2.0.0',
             'scikit-learn[sklearn]>=1.1.1,<2.0.0']}

entry_points = \
{'console_scripts': ['inseq = inseq.commands.cli:main']}

setup_kwargs = {
    'name': 'inseq',
    'version': '0.4.0',
    'description': 'Interpretability for Sequence Generation Models üîç',
    'long_description': '<div align="center">\n  <img src="https://raw.githubusercontent.com/inseq-team/inseq/main/docs/source/images/inseq_logo.png" width="300"/>\n  <h4>Intepretability for Sequence Generation Models üîç</h4>\n</div>\n<br/>\n<div align="center">\n\n\n[![Build status](https://img.shields.io/github/actions/workflow/status/inseq-team/inseq/build.yml?branch=main)](https://github.com/inseq-team/inseq/actions?query=workflow%3Abuild)\n[![Docs status](https://img.shields.io/readthedocs/inseq)](https://inseq.readthedocs.io)\n[![Version](https://img.shields.io/pypi/v/inseq?color=blue)](https://pypi.org/project/inseq/)\n[![Python Version](https://img.shields.io/pypi/pyversions/inseq.svg?color=blue)](https://pypi.org/project/inseq/)\n[![Downloads](https://static.pepy.tech/badge/inseq)](https://pepy.tech/project/inseq)\n[![License](https://img.shields.io/github/license/inseq-team/inseq)](https://github.com/inseq-team/inseq/blob/main/LICENSE)\n\n</div>\n<div align="center">\n\n\n  [![Follow Inseq on Twitter](https://img.shields.io/twitter/follow/inseqlib?label=InseqLib&style=social)](https://twitter.com/InseqLib)\n  [![Follow Inseq on Mastodon](https://img.shields.io/mastodon/follow/109308976376923913?domain=https%3A%2F%2Fsigmoid.social&label=Inseq&style=social)](https://sigmoid.social/@inseq)\n</div>\n\nInseq is a Pytorch-based hackable toolkit to democratize the access to common post-hoc **in**terpretability analyses of **seq**uence generation models.\n\n- Documentation: [https://inseq.readthedocs.io](https//inseq.readthedocs.io)\n- Paper: **Coming soon!**\n- PyPI Package: [https://pypi.org/project/inseq](https://pypi.org/project/inseq)\n- MT Gender Bias Demo: [oskarvanderwal/MT-bias-demo](https://huggingface.co/spaces/oskarvanderwal/MT-bias-demo)\n\n## Installation\n\nInseq is available on PyPI and can be installed with `pip`:\n\n```bash\n# Install latest stable version\npip install inseq\n\n# Alternatively, install latest development version\npip install git+https://github.com/inseq-team/inseq.git\n```\n\nInstall extras for visualization in Jupyter Notebooks and ü§ó datasets attribution as `pip install inseq[notebook,datasets]`.\n\n<details>\n  <summary>Dev Installation</summary>\nTo install the package, clone the repository and run the following commands:\n\n```bash\ncd inseq\nmake poetry-download # Download and install the Poetry package manager\nmake install # Installs the package and all dependencies\n```\n\nIf you have a GPU available, use `make install-gpu` to install the latest `torch` version with GPU support.\n\nFor library developers, you can use the `make install-dev` command to install and its GPU-friendly counterpart `make install-dev-gpu` to install all development dependencies (quality, docs, extras).\n\nAfter installation, you should be able to run `make fast-test` and `make lint` without errors.\n</details>\n\n<details>\n  <summary>FAQ Installation</summary>\n\n- Installing the `tokenizers` package requires a Rust compiler installation. You can install Rust from [https://rustup.rs](https://rustup.rs) and add `$HOME/.cargo/env` to your PATH.\n\n- Installing `sentencepiece` requires various packages, install with `sudo apt-get install cmake build-essential pkg-config` or `brew install cmake gperftools pkg-config`.\n\n</details>\n\n## Example usage in Python\n\nThis example uses the Integrated Gradients attribution method to attribute the English-French translation of a sentence taken from the WinoMT corpus:\n\n```python\nimport inseq\n\nmodel = inseq.load_model("Helsinki-NLP/opus-mt-en-fr", "integrated_gradients")\nout = model.attribute(\n  "The developer argued with the designer because her idea cannot be implemented.",\n  n_steps=100\n)\nout.show()\n```\n\nThis produces a visualization of the attribution scores for each token in the input sentence (token-level aggregation is handled automatically). Here is what the visualization looks like inside a Jupyter Notebook:\n\n![WinoMT Attribution Map](https://raw.githubusercontent.com/inseq-team/inseq/main/docs/source/images/heatmap_winomt.png)\n\nInseq also supports decoder-only models such as [GPT-2](https://huggingface.co/transformers/model_doc/gpt2.html), enabling usage of a variety of attribution methods and customizable settings directly from the console:\n\n```python\nimport inseq\n\nmodel = inseq.load_model("gpt2", "integrated_gradients")\nmodel.attribute(\n    "Hello ladies and",\n    generation_args={"max_new_tokens": 9},\n    n_steps=500,\n    internal_batch_size=50\n).show()\n```\n\n![GPT-2 Attribution in the console](https://raw.githubusercontent.com/inseq-team/inseq/main/docs/source/images/inseq_python_console.gif)\n\n## Features\n\n- üöÄ Feature attribution of sequence generation for most `ForConditionalGeneration` (encoder-decoder) and `ForCausalLM` (decoder-only) models from ü§ó Transformers\n\n- üöÄ Support for multiple feature attribution methods, sourced in part from [Captum](https://captum.ai/docs/introduction)\n\n- üöÄ Post-processing of attribution maps via `Aggregator` classes.\n\n- üöÄ Attribution visualization in notebooks, browser and command line.\n\n- üöÄ Attribute single examples or entire ü§ó datasets with the Inseq CLI.\n\n- üöÄ Custom attribution of target functions, supporting advanced use cases such as contrastive and uncertainty-weighted feature attributions.\n\n- üöÄ Extraction and visualization of custom step scores (e.g. probability, entropy) alongsides attribution maps.\n\n### Supported methods\n\nUse the `inseq.list_feature_attribution_methods` function to list all available method identifiers and `inseq.list_step_functions` to list all available step functions. The following methods are currently supported:\n\n#### Gradient-based attribution\n\n- `saliency`: [Saliency](https://arxiv.org/abs/1312.6034) (Simonyan et al., 2013)\n\n- `input_x_gradient`: [Input x Gradient](https://arxiv.org/abs/1312.6034) (Simonyan et al., 2013)\n\n- `integrated_gradients`: [Integrated Gradients](https://arxiv.org/abs/1703.01365) (Sundararajan et al., 2017)\n\n- `deeplift`: [DeepLIFT](https://arxiv.org/abs/1704.02685) (Shrikumar et al., 2017)\n\n- `gradient_shap`: [Gradient SHAP](https://dl.acm.org/doi/10.5555/3295222.3295230) (Lundberg and Lee, 2017)\n\n- `discretized_integrated_gradients`: [Discretized Integrated Gradients](https://aclanthology.org/2021.emnlp-main.805/) (Sanyal and Ren, 2021)\n\n#### Internals-based attribution\n\n- `attention`: [Attention Weight Attribution](https://arxiv.org/abs/1409.0473) (Bahdanau et al., 2014)\n\n#### Perturbation-based attribution\n\n- `occlusion`: [Occlusion](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53) (Zeiler and Fergus, 2014)\n\n- `lime`: [LIME](https://arxiv.org/abs/1602.04938) (Ribeiro et al., 2016)\n\n#### Step functions\n\nStep functions are used to extract custom scores from the model at each step of the attribution process with the `step_scores` argument in `model.attribute`. They can also be used as targets for attribution methods relying on model outputs (e.g. gradient-based methods) by passing them as the `attributed_fn` argument. The following step functions are currently supported:\n\n- `logits`: Logits of the target token.\n- `probability`: Probability of the target token.\n- `entropy`: Entropy of the predictive distribution.\n- `crossentropy`: Cross-entropy loss between target token and predicted distribution.\n- `perplexity`: Perplexity of the target token.\n- `contrast_prob_diff`: Difference in probability between the target token and a foil token used for contrastive evaluation as in [Contrastive Attribution](https://aclanthology.org/2022.emnlp-main.14/) (Yin and Neubig, 2022).\n- `mc_dropout_prob_avg`: Average probability of the target token across multiple samples using [MC Dropout](https://arxiv.org/abs/1506.02142) (Gal and Ghahramani, 2016).\n\nThe following example computes contrastive attributions using the `contrast_prob_diff` step function:\n\n```python\nimport inseq\n\nattribution_model = inseq.load_model("gpt2", "input_x_gradient")\n\n# Pre-compute ids and attention map for the contrastive target\ncontrast = attribution_model.encode("Can you stop the dog from crying")\n\n# Perform the contrastive attribution:\n# Regular (forced) target -> "Can you stop the dog from barking"\n# Contrastive target      -> "Can you stop the dog from crying"\nout = attribution_model.attribute(\n    "Can you stop the dog from",\n    "Can you stop the dog from barking",\n    attributed_fn="contrast_prob_diff",\n    contrast_ids=contrast.input_ids,\n    contrast_attention_mask=contrast.attention_mask,\n    # We also visualize the corresponding step score\n    step_scores=["contrast_prob_diff"]\n)\nout.show()\n```\n\nRefer to the [documentation](https://inseq.readthedocs.io/examples/custom_attribute_target.html) for an example including custom function registration.\n\n## Using the Inseq client\n\nThe Inseq library also provides useful client commands to enable repeated attribution of individual examples and even entire ü§ó datasets directly from the console. See the available options by typing `inseq -h` in the terminal after installing the package.\n\nFor now, two commands are supported:\n\n- `√¨nseq attribute`: Wraps the `attribute` method shown above, requires explicit inputs to be attributed.\n\n- `inseq attribute-dataset`: Enables attribution for a full dataset using Hugging Face `datasets.load_dataset`.\n\nBoth commands support the full range of parameters available for `attribute`, attribution visualization in the console and saving outputs to disk.\n\n**Example:** The following command can be used to perform attribution (both source and target-side) of Italian translations for a dummy sample of 20 English sentences taken from the FLORES-101 parallel corpus, using a MarianNMT translation model from Hugging Face `transformers`. We save the visualizations in HTML format in the file `attributions.html`. See the `--help` flag for more options.\n\n```bash\ninseq attribute-dataset \\\n  --model_name_or_path Helsinki-NLP/opus-mt-en-it \\\n  --attribution_method saliency \\\n  --do_prefix_attribution \\\n  --dataset_name inseq/dummy_enit \\\n  --input_text_field en \\\n  --dataset_split "train[:20]" \\\n  --viz_path attributions.html \\\n  --batch_size 8 \\\n  --hide\n```\n\n## Planned Development\n\n- ‚öôÔ∏è Support more attention-based and occlusion-based feature attribution methods (documented in [#107](https://github.com/inseq-team/inseq/issues/107) and [#108](https://github.com/inseq-team/inseq/issues/108)).\n\n- ‚öôÔ∏è Interoperability with [ferret](https://ferret.readthedocs.io/en/latest/) for attribution plausibility and faithfulness evaluation.\n\n- ‚öôÔ∏è Rich and interactive visualizations in a tabbed interface using [Gradio Blocks](https://gradio.app/docs/#blocks).\n\n## Contributing\n\nOur vision for Inseq is to create a centralized, comprehensive and robust set of tools to enable fair and reproducible comparisons in the study of sequence generation models. To achieve this goal, contributions from researchers and developers interested in these topics are more than welcome. Please see our [contributing guidelines](CONTRIBUTING.md) and our [code of conduct](CODE_OF_CONDUCT.md) for more information.\n\n## Citing Inseq\n\nA demo paper showcasing the Inseq library is presently in the works. In the meantime, if you use Inseq we kindly ask you to include the link `https://github.com/inseq-team/inseq` as a footnote and cite it as:\n\n```bibtex\n@software{inseq,\n  author    = {Sarti, Gabriele and Sickert, Ludwig and Feldhus, Nils and van der Wal, Oskar},\n  title     = {Inseq: An Interpretability Toolkit for Sequence Generation Models},\n  month     = jan,\n  year      = 2023,\n  publisher = {Zenodo},\n  version   = {0.3.3},\n  doi       = {10.5281/zenodo.7550249},\n  url       = {https://doi.org/10.5281/zenodo.7550249}\n}\n```\n',
    'author': 'The Inseq Team',
    'author_email': 'None',
    'maintainer': 'gsarti',
    'maintainer_email': 'gabriele.sarti996@gmail.com',
    'url': 'https://github.com/inseq-team/inseq',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'extras_require': extras_require,
    'entry_points': entry_points,
    'python_requires': '>=3.8.1,<3.12',
}


setup(**setup_kwargs)
