{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e94e513",
   "metadata": {},
   "source": [
    "## scripts to evaluate matching results (antibody drop version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5e6a7",
   "metadata": {},
   "source": [
    "calculation of matching accuracy, foscknn, foscttm and retrieve slt ari f1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ed6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e997f53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkzhu/super_mario/bench_test3/scripts_benchmark/metrics.py:98: RuntimeWarning: invalid value encountered in true_divide\n",
      "  indices2_and_scores[1] = list(np.array(indices2_and_scores[1]) / np.sum(indices2_and_scores[1]))\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"/bench_test3/output/drop/\"\n",
    "ann_list1 = []\n",
    "ann_list2 = []\n",
    "foscttm_list = []\n",
    "tmp = []\n",
    "knn_tmp = []\n",
    "slt_f1 = []\n",
    "ari_f1 = []\n",
    "\n",
    "for i in range(5):\n",
    "    batch = 'b'+str(i+1)+'/'\n",
    "    for j in range(4):\n",
    "        \n",
    "        drop_name = \"dropLV\"+str(j)+\"/\"\n",
    "        root_dir = out_dir+batch+drop_name\n",
    "        # produce liger matching\n",
    "        lgx = pd.read_csv(root_dir+\"lgunimf/full_embed_x0.csv\")\n",
    "        lgy = pd.read_csv(root_dir+\"lgunimf/full_embed_y0.csv\")\n",
    "        lg_dist = utils.cdist_correlation(lgy.to_numpy(), lgx.to_numpy())\n",
    "        lg_full_match, lg_scores = metrics.get_knn_matching(lg_dist)\n",
    "        lgmatch = [lg_full_match,np.arange(lgy.shape[0]),lg_scores]\n",
    "        # produce bsc matching\n",
    "        bscx = pd.read_csv(root_dir+\"bsc/full_embed_x0.csv\")\n",
    "        bscy = pd.read_csv(root_dir+\"bsc/full_embed_y0.csv\")\n",
    "        bsc_dist = utils.cdist_correlation(bscy.to_numpy(), bscx.to_numpy())\n",
    "        bsc_full_match, bsc_scores = metrics.get_knn_matching(bsc_dist)\n",
    "        bscmatch = [bsc_full_match,np.arange(bscx.shape[0]),bsc_scores]\n",
    "        # harmony matching\n",
    "        hmx = pd.read_csv(root_dir+\"hm/full_embed_x0.csv\")\n",
    "        hmy = pd.read_csv(root_dir+\"hm/full_embed_y0.csv\")\n",
    "        hm_dist = utils.cdist_correlation(hmy.to_numpy(), hmx.to_numpy())\n",
    "        hm_full_match, hm_scores = metrics.get_knn_matching(hm_dist)\n",
    "        hmmatch = [hm_full_match,np.arange(hmx.shape[0]),hm_scores]\n",
    "        # load mf matching\n",
    "        mf = pd.read_csv(root_dir+\"mf/full_idx.csv\")\n",
    "        mfmatch = [mf['idx1'].tolist(),mf['idx2'].tolist(),mf['score'].tolist()]\n",
    "        # load sr matching\n",
    "        #sr = pd.read_csv(root_dir+\"sr/full_idx.csv\")\n",
    "        #srmatch = [sr['idx1'].tolist(),sr['idx2'].tolist(),sr['score'].tolist()]\n",
    "        srx = pd.read_csv(root_dir+\"sr/full_embed_x0.csv\")\n",
    "        sry = pd.read_csv(root_dir+\"sr/full_embed_y0.csv\")\n",
    "        sr_dist = utils.cdist_correlation(sry.to_numpy(), srx.to_numpy())\n",
    "        sr_full_match, sr_scores = metrics.get_knn_matching(sr_dist)\n",
    "        srmatch = [sr_full_match,np.arange(sry.shape[0]),sr_scores]\n",
    "        # load embedding too\n",
    "        # mf embed\n",
    "        mfx = pd.read_csv(root_dir+\"mf/full_embed_x0.csv\")\n",
    "        mfy = pd.read_csv(root_dir+\"mf/full_embed_y0.csv\")\n",
    "        # sr embed\n",
    "        #srx = pd.read_csv(root_dir+\"sr/full_embed_x0.csv\")\n",
    "        #sry = pd.read_csv(root_dir+\"sr/full_embed_y0.csv\")\n",
    "        # read meta info\n",
    "        temp_dir = '/home/bkzhu/super_mario/bench_test3/input/'\n",
    "        meta = pd.read_csv(temp_dir + batch+ 'meta.csv')\n",
    "        annotationlv1 = meta['celltype.l1'].to_numpy()\n",
    "        order = (2, 1)\n",
    "        acc_ann_hm = metrics.get_matching_acc(\n",
    "                matching=hmmatch, \n",
    "                labels1=annotationlv1, \n",
    "                labels2=annotationlv1,\n",
    "                order = order\n",
    "            )\n",
    "\n",
    "        acc_ann_lg = metrics.get_matching_acc(\n",
    "                matching=lgmatch, \n",
    "                labels1=annotationlv1, \n",
    "                labels2=annotationlv1,\n",
    "                order = order\n",
    "            )\n",
    "\n",
    "        acc_ann_sr = metrics.get_matching_acc(\n",
    "                matching=srmatch, \n",
    "                labels1=annotationlv1, \n",
    "                labels2=annotationlv1,\n",
    "                order = order\n",
    "            )\n",
    "\n",
    "        acc_ann_mf = metrics.get_matching_acc(\n",
    "                matching=mfmatch, \n",
    "                labels1=annotationlv1, \n",
    "                labels2=annotationlv1,\n",
    "                order = order\n",
    "            )\n",
    "        \n",
    "        acc_ann_bsc = metrics.get_matching_acc(\n",
    "            matching=bscmatch, \n",
    "            labels1=annotationlv1, \n",
    "            labels2=annotationlv1,\n",
    "            order = order\n",
    "        )\n",
    "        ann_list1.extend([acc_ann_mf, acc_ann_sr, acc_ann_lg, acc_ann_hm, acc_ann_bsc])\n",
    "        #\n",
    "        annotationlv2 = meta['celltype.l2'].to_numpy()\n",
    "        order = (2, 1)\n",
    "        acc_ann_hm = metrics.get_matching_acc(\n",
    "                matching=hmmatch, \n",
    "                labels1=annotationlv2, \n",
    "                labels2=annotationlv2,\n",
    "                order = order\n",
    "            )\n",
    "\n",
    "        acc_ann_lg = metrics.get_matching_acc(\n",
    "                matching=lgmatch, \n",
    "                labels1=annotationlv2, \n",
    "                labels2=annotationlv2,\n",
    "                order = order\n",
    "            )\n",
    "\n",
    "        acc_ann_sr = metrics.get_matching_acc(\n",
    "                matching=srmatch, \n",
    "                labels1=annotationlv2, \n",
    "                labels2=annotationlv2,\n",
    "                order = order\n",
    "            )\n",
    "        acc_ann_mf = metrics.get_matching_acc(\n",
    "                matching=mfmatch, \n",
    "                labels1=annotationlv2, \n",
    "                labels2=annotationlv2,\n",
    "                order = order\n",
    "            )\n",
    "        acc_ann_bsc = metrics.get_matching_acc(\n",
    "            matching=bscmatch, \n",
    "            labels1=annotationlv2, \n",
    "            labels2=annotationlv2,\n",
    "            order = order\n",
    "        )\n",
    "        ann_list2.extend([acc_ann_mf, acc_ann_sr, acc_ann_lg, acc_ann_hm, acc_ann_bsc])\n",
    "        # foscttm\n",
    "        # mf\n",
    "        mfdist = utils.cdist_correlation(mfx.to_numpy(), mfy.to_numpy())\n",
    "        mf_fos = metrics.get_foscttm(mfdist)\n",
    "        # sr\n",
    "        srdist = utils.cdist_correlation(srx.to_numpy(), sry.to_numpy())\n",
    "        sr_fos = metrics.get_foscttm(srdist)\n",
    "        # lg\n",
    "        lg_fos = metrics.get_foscttm(lg_dist)\n",
    "        # hm\n",
    "        hm_fos = metrics.get_foscttm(hm_dist)\n",
    "        # bsc\n",
    "        bsc_fos = metrics.get_foscttm(bsc_dist)\n",
    "        foscttm_list.extend([mf_fos,sr_fos,lg_fos,hm_fos,bsc_fos])\n",
    "        # single-cell level accuracy\n",
    "        mfsc = metrics.get_matching_alignment_score(mfmatch,n_samples=lgy.shape[0])\n",
    "        srsc = metrics.get_matching_alignment_score(srmatch,n_samples=lgy.shape[0])\n",
    "        lgsc = metrics.get_matching_alignment_score(lgmatch,n_samples=lgy.shape[0])\n",
    "        hmsc = metrics.get_matching_alignment_score(hmmatch,n_samples=lgy.shape[0])\n",
    "        bscsc = metrics.get_matching_alignment_score(bscmatch,n_samples=lgy.shape[0])\n",
    "        tmp.extend([mfsc,srsc,lgsc,hmsc,bscsc])\n",
    "        # knn search tmp\n",
    "        k = 100\n",
    "        knn_match_mf = metrics.get_knn_alignment_score(\n",
    "            dist=mfdist,\n",
    "            k_max=k\n",
    "        )\n",
    "        knn_match_sr = metrics.get_knn_alignment_score(\n",
    "            dist=srdist,\n",
    "            k_max=k\n",
    "        )\n",
    "        knn_match_lg = metrics.get_knn_alignment_score(\n",
    "            dist=lg_dist,\n",
    "            k_max=k\n",
    "        )\n",
    "        knn_match_hm = metrics.get_knn_alignment_score(\n",
    "            dist=hm_dist,\n",
    "            k_max=k\n",
    "        )\n",
    "        knn_match_bsc = metrics.get_knn_alignment_score(\n",
    "            dist=bsc_dist,\n",
    "            k_max=k\n",
    "        )\n",
    "        # store the knn tmp\n",
    "        knn_tmp.extend([knn_match_mf.tolist(), knn_match_sr.tolist(),\n",
    "                        knn_match_lg.tolist(), knn_match_hm.tolist(), knn_match_bsc.tolist()])\n",
    "        # also need to read the integration metrics\n",
    "        mf_met = pd.read_csv(root_dir+\"mf/metrics.csv\")\n",
    "        sr_met = pd.read_csv(root_dir+\"sr/metrics.csv\")\n",
    "        lg_met = pd.read_csv(root_dir+\"lg/metrics.csv\")\n",
    "        hm_met = pd.read_csv(root_dir+\"hm/metrics.csv\")\n",
    "\n",
    "        slt_f1.extend([mf_met.loc[0,'slt_f1'],sr_met.loc[0,'slt_f1'],lg_met.loc[0,'slt_f1'],hm_met.loc[0,'slt_f1']])\n",
    "        ari_f1.extend([mf_met.loc[0,'ari_f1'],sr_met.loc[0,'ari_f1'],lg_met.loc[0,'ari_f1'],hm_met.loc[0,'ari_f1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a679dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct batch\n",
    "b = np.array([\"b1\",\"b2\",\"b3\",\"b4\",\"b5\"])\n",
    "binfo = np.repeat(b, [20,20,20,20,20], axis=0)\n",
    "m = [\"mf\",\"sr\",\"lg\",\"hm\",\"bsc\"]\n",
    "minfo = m*5*4\n",
    "\n",
    "drop = [\"dropLv0\",\"dropLv1\",\"dropLv2\",\"dropLv3\"]\n",
    "dropinfo = np.repeat(drop, [5,5,5,5], axis=0).tolist()\n",
    "dropinfo = dropinfo*5\n",
    "\n",
    "data = {'batch':binfo, 'method':minfo,'drop':dropinfo,\n",
    "       'ann1':ann_list1, 'ann2':ann_list2, 'foscttm':foscttm_list, 'tmp':tmp }\n",
    "\n",
    "matching_result = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b4b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_result.to_csv(\"/bench_test3/output/drop4_batch5_resultsV2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99bd9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct batch\n",
    "b = np.array([\"b1\",\"b2\",\"b3\",\"b4\",\"b5\"])\n",
    "binfo = np.repeat(b,[100*4*5,100*4*5,100*4*5,100*4*5,100*4*5], axis=0).tolist()\n",
    "\n",
    "m = np.array([\"mf\", \"sr\",\"lg\",\"hm\",\"bsc\"])\n",
    "minfo = np.repeat(m, [100,100,100,100,100], axis=0).tolist()\n",
    "minfo2 = minfo * 4 * 5\n",
    "\n",
    "knn = [item for sublist in knn_tmp for item in sublist]\n",
    "step = [i for i in range(100)]*4*5*5\n",
    "\n",
    "drop = [\"dropLv0\",\"dropLv1\",\"dropLv2\",\"dropLv3\"]\n",
    "dropinfo = np.repeat(drop, [100*5,100*5,100*5,100*5], axis=0).tolist()\n",
    "dropinfo = dropinfo*5\n",
    "\n",
    "data = {'batch':binfo, 'method':minfo2,'knn_tmp': knn, 'step':step, 'drop': dropinfo}\n",
    "\n",
    "knn_result = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6412e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results as csvs\n",
    "knn_result.to_csv(\"/bench_test3/output/drop4_batch5_knntmpV2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b0d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
