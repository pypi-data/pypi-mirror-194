{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e94e513",
   "metadata": {},
   "source": [
    "## scripts to evaluate matching results (full panel version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78219135",
   "metadata": {},
   "source": [
    "calculation of matching accuracy, foscknn, foscttm and retrieve slt ari f1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ed6a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bkzhu/python/miniconda3/envs/super_mario_testing/bin/python3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "import metrics\n",
    "import utils\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f2c4b9",
   "metadata": {},
   "source": [
    "### verdict: unimf actually will worsen the performance so just use vanilla??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e997f53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkzhu/super_mario/bench_test3/scripts_benchmark/metrics.py:98: RuntimeWarning: invalid value encountered in true_divide\n",
      "  indices2_and_scores[1] = list(np.array(indices2_and_scores[1]) / np.sum(indices2_and_scores[1]))\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"/bench_test3/output/\"\n",
    "ann_listlv1 = []\n",
    "ann_listlv2 = []\n",
    "foscttm_list = []\n",
    "tmp = []\n",
    "knn_tmp = []\n",
    "slt_f1 = []\n",
    "ari_f1 = []\n",
    "\n",
    "for i in range(5):\n",
    "    batch = 'b'+str(i+1)+'/'\n",
    "    root_dir = out_dir+batch\n",
    "    # produce liger matching\n",
    "    lgx = pd.read_csv(root_dir+\"lg/full_embed_x0.csv\")\n",
    "    lgy = pd.read_csv(root_dir+\"lg/full_embed_y0.csv\")\n",
    "    lg_dist = utils.cdist_correlation(lgy.to_numpy(), lgx.to_numpy())\n",
    "    lg_full_match, lg_scores = metrics.get_knn_matching(lg_dist)\n",
    "    lgmatch = [lg_full_match,np.arange(lgy.shape[0]),lg_scores]\n",
    "    # produce liger matching\n",
    "    bscx = pd.read_csv(root_dir+\"bsc/full_embed_x0.csv\")\n",
    "    bscy = pd.read_csv(root_dir+\"bsc/full_embed_y0.csv\")\n",
    "    bsc_dist = utils.cdist_correlation(bscy.to_numpy(), bscx.to_numpy())\n",
    "    bsc_full_match, bsc_scores = metrics.get_knn_matching(bsc_dist)\n",
    "    bscmatch = [bsc_full_match,np.arange(bscy.shape[0]),bsc_scores]\n",
    "    # harmony matching\n",
    "    hmx = pd.read_csv(root_dir+\"hm/full_embed_x0.csv\")\n",
    "    hmy = pd.read_csv(root_dir+\"hm/full_embed_y0.csv\")\n",
    "    hm_dist = utils.cdist_correlation(hmy.to_numpy(), hmx.to_numpy())\n",
    "    hm_full_match, hm_scores = metrics.get_knn_matching(hm_dist)\n",
    "    hmmatch = [hm_full_match,np.arange(hmy.shape[0]),hm_scores]\n",
    "    # load mf matching\n",
    "    mf = pd.read_csv(root_dir+\"mf/full_idx.csv\")\n",
    "    mfmatch = [mf['idx1'].tolist(),mf['idx2'].tolist(),mf['score'].tolist()]\n",
    "    # load sr matching\n",
    "    #sr = pd.read_csv(root_dir+\"sr/full_idx.csv\")\n",
    "    #srmatch = [sr['idx1'].tolist(),sr['idx2'].tolist(),sr['score'].tolist()]\n",
    "    srx = pd.read_csv(root_dir+\"sr/full_embed_x0.csv\")\n",
    "    sry = pd.read_csv(root_dir+\"sr/full_embed_y0.csv\")\n",
    "    sr_dist = utils.cdist_correlation(sry.to_numpy(), srx.to_numpy())\n",
    "    sr_full_match, sr_scores = metrics.get_knn_matching(sr_dist)\n",
    "    srmatch = [sr_full_match,np.arange(sry.shape[0]),sr_scores]\n",
    "    # load embedding too\n",
    "    # mf embed\n",
    "    mfx = pd.read_csv(root_dir+\"mf/full_embed_x0.csv\")\n",
    "    mfy = pd.read_csv(root_dir+\"mf/full_embed_y0.csv\")\n",
    "    # sr embed\n",
    "    #srx = pd.read_csv(root_dir+\"sr/full_embed_x0.csv\")\n",
    "    #sry = pd.read_csv(root_dir+\"sr/full_embed_y0.csv\")\n",
    "    # read meta info\n",
    "    temp_dir = '/home/bkzhu/super_mario/bench_test3/input/'\n",
    "    meta = pd.read_csv(temp_dir + batch+ 'meta.csv')\n",
    "    annotationlv1 = meta['celltype.l1'].to_numpy()\n",
    "    order = (2, 1)\n",
    "    acc_ann_hm = metrics.get_matching_acc(\n",
    "            matching=hmmatch, \n",
    "            labels1=annotationlv1, \n",
    "            labels2=annotationlv1,\n",
    "            order = order\n",
    "        )\n",
    "\n",
    "    acc_ann_bsc = metrics.get_matching_acc(\n",
    "            matching=bscmatch, \n",
    "            labels1=annotationlv1, \n",
    "            labels2=annotationlv1,\n",
    "            order = order\n",
    "        )\n",
    "    \n",
    "    acc_ann_lg = metrics.get_matching_acc(\n",
    "            matching=lgmatch, \n",
    "            labels1=annotationlv1, \n",
    "            labels2=annotationlv1,\n",
    "            order = order\n",
    "        )\n",
    "\n",
    "    acc_ann_sr = metrics.get_matching_acc(\n",
    "            matching=srmatch, \n",
    "            labels1=annotationlv1, \n",
    "            labels2=annotationlv1,\n",
    "            order = order\n",
    "        )\n",
    "\n",
    "    acc_ann_mf = metrics.get_matching_acc(\n",
    "            matching=mfmatch, \n",
    "            labels1=annotationlv1, \n",
    "            labels2=annotationlv1,\n",
    "            order = order\n",
    "        )\n",
    "    ann_listlv1.extend([acc_ann_mf, acc_ann_sr, acc_ann_lg, acc_ann_hm, acc_ann_bsc])\n",
    "    # lv2\n",
    "    annotationlv2 = meta['celltype.l2'].to_numpy()\n",
    "    order = (2, 1)\n",
    "    acc_ann_hm = metrics.get_matching_acc(\n",
    "            matching=hmmatch, \n",
    "            labels1=annotationlv2, \n",
    "            labels2=annotationlv2,\n",
    "            order = order\n",
    "        )\n",
    "\n",
    "    acc_ann_lg = metrics.get_matching_acc(\n",
    "            matching=lgmatch, \n",
    "            labels1=annotationlv2, \n",
    "            labels2=annotationlv2,\n",
    "            order = order\n",
    "        )\n",
    "    \n",
    "    acc_ann_bsc = metrics.get_matching_acc(\n",
    "            matching=bscmatch, \n",
    "            labels1=annotationlv2, \n",
    "            labels2=annotationlv2,\n",
    "            order = order\n",
    "        )\n",
    "\n",
    "    acc_ann_sr = metrics.get_matching_acc(\n",
    "            matching=srmatch, \n",
    "            labels1=annotationlv2, \n",
    "            labels2=annotationlv2,\n",
    "            order = order\n",
    "        )\n",
    "\n",
    "    acc_ann_mf = metrics.get_matching_acc(\n",
    "            matching=mfmatch, \n",
    "            labels1=annotationlv2, \n",
    "            labels2=annotationlv2,\n",
    "            order = order\n",
    "        )\n",
    "    ann_listlv2.extend([acc_ann_mf, acc_ann_sr, acc_ann_lg, acc_ann_hm, acc_ann_bsc])\n",
    "    # foscttm\n",
    "    # mf\n",
    "    mfdist = utils.cdist_correlation(mfx.to_numpy(), mfy.to_numpy())\n",
    "    mf_fos = metrics.get_foscttm(mfdist)\n",
    "    # sr\n",
    "    srdist = utils.cdist_correlation(srx.to_numpy(), sry.to_numpy())\n",
    "    sr_fos = metrics.get_foscttm(srdist)\n",
    "    # lg\n",
    "    lg_fos = metrics.get_foscttm(lg_dist)\n",
    "    # bsc\n",
    "    bsc_fos = metrics.get_foscttm(bsc_dist)\n",
    "    # hm\n",
    "    hm_fos = metrics.get_foscttm(hm_dist)\n",
    "    foscttm_list.extend([mf_fos,sr_fos,lg_fos,hm_fos,bsc_fos])\n",
    "    # single-cell level accuracy\n",
    "    mfsc = metrics.get_matching_alignment_score(mfmatch,n_samples=lgy.shape[0])\n",
    "    srsc = metrics.get_matching_alignment_score(srmatch,n_samples=lgy.shape[0])\n",
    "    lgsc = metrics.get_matching_alignment_score(lgmatch,n_samples=lgy.shape[0])\n",
    "    bscsc = metrics.get_matching_alignment_score(bscmatch,n_samples=bscy.shape[0])\n",
    "    hmsc = metrics.get_matching_alignment_score(hmmatch,n_samples=lgy.shape[0])\n",
    "    tmp.extend([mfsc,srsc,lgsc,hmsc,bscsc])\n",
    "    # knn search tmp\n",
    "    k = 100\n",
    "    knn_match_mf = metrics.get_knn_alignment_score(\n",
    "        dist=mfdist,\n",
    "        k_max=k\n",
    "    )\n",
    "    knn_match_sr = metrics.get_knn_alignment_score(\n",
    "        dist=srdist,\n",
    "        k_max=k\n",
    "    )\n",
    "    knn_match_lg = metrics.get_knn_alignment_score(\n",
    "        dist=lg_dist,\n",
    "        k_max=k\n",
    "    )\n",
    "    knn_match_bsc = metrics.get_knn_alignment_score(\n",
    "        dist=bsc_dist,\n",
    "        k_max=k\n",
    "    )\n",
    "    knn_match_hm = metrics.get_knn_alignment_score(\n",
    "        dist=hm_dist,\n",
    "        k_max=k\n",
    "    )\n",
    "    # store the knn tmp\n",
    "    knn_tmp.extend([knn_match_mf.tolist(), knn_match_sr.tolist(),\n",
    "                    knn_match_lg.tolist(), knn_match_hm.tolist(), knn_match_bsc.tolist()])\n",
    "    # also need to read the integration metrics\n",
    "    mf_met = pd.read_csv(root_dir+\"mf/metrics.csv\")\n",
    "    sr_met = pd.read_csv(root_dir+\"sr/metrics.csv\")\n",
    "    lg_met = pd.read_csv(root_dir+\"lgunimf/metrics.csv\")\n",
    "    bsc_met = pd.read_csv(root_dir+\"bsc/metrics.csv\")\n",
    "    hm_met = pd.read_csv(root_dir+\"hm/metrics.csv\")\n",
    "\n",
    "    slt_f1.extend([mf_met.loc[0,'slt_f1'],sr_met.loc[0,'slt_f1'],\n",
    "                   lg_met.loc[0,'slt_f1'],hm_met.loc[0,'slt_f1'], bsc_met.loc[0,'slt_f1'] ])\n",
    "    ari_f1.extend([mf_met.loc[0,'ari_f1'],sr_met.loc[0,'ari_f1'],\n",
    "                   lg_met.loc[0,'ari_f1'],hm_met.loc[0,'ari_f1'], bsc_met.loc[0,'ari_f1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a679dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct batch\n",
    "b = np.array([\"b1\",\"b2\",\"b3\",\"b4\",\"b5\"])\n",
    "binfo = np.repeat(b, [5,5,5,5,5], axis=0)\n",
    "m = [\"mf\",\"sr\",\"lg\",\"hm\", \"bsc\"]\n",
    "minfo = m*5\n",
    "\n",
    "data = {'batch':binfo, 'method':minfo,'slt_f1': slt_f1, 'ari_f1':ari_f1,\n",
    "       'ann1':ann_listlv1, 'ann2':ann_listlv2, 'foscttm':foscttm_list, 'tmp':tmp }\n",
    "\n",
    "matching_result = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20b7bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct batch\n",
    "b = np.array([\"b1\",\"b2\",\"b3\",\"b4\",\"b5\"])\n",
    "binfo = np.repeat(b,[500,500,500,500,500], axis=0).tolist()\n",
    "m = np.array([\"mf\", \"sr\",\"lg\",\"hm\",\"bsc\"])\n",
    "minfo = np.repeat(m, [100,100,100,100,100], axis=0).tolist()\n",
    "minfo2 = minfo * 5\n",
    "knn = [item for sublist in knn_tmp for item in sublist]\n",
    "step = [i for i in range(100)]*5*5\n",
    "data = {'batch':binfo, 'method':minfo2,'knn_tmp': knn, 'step':step }\n",
    "\n",
    "knn_result = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f733fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_result.to_csv(\"/bench_test3/output/batch5_resultsV2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99bd9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct batch\n",
    "b = np.array([\"b1\",\"b2\",\"b3\",\"b4\",\"b5\"])\n",
    "binfo = np.repeat(b,[500,500,500,500,500], axis=0).tolist()\n",
    "m = np.array([\"mf\", \"sr\",\"lg\",\"hm\",\"bsc\"])\n",
    "minfo = np.repeat(m, [100,100,100,100,100], axis=0).tolist()\n",
    "minfo2 = minfo * 5\n",
    "knn = [item for sublist in knn_tmp for item in sublist]\n",
    "step = [i for i in range(100)]*5*5\n",
    "data = {'batch':binfo, 'method':minfo2,'knn_tmp': knn, 'step':step }\n",
    "\n",
    "knn_result = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b6412e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results as csvs\n",
    "knn_result.to_csv(\"/bench_test3/output/batch5_knntmpV2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
