# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['pymedquery',
 'pymedquery.config',
 'pymedquery.docs',
 'pymedquery.sql.default',
 'pymedquery.src']

package_data = \
{'': ['*'],
 'pymedquery': ['data/processed/*', 'data/sql/*'],
 'pymedquery.docs': ['proj_logging/*']}

install_requires = \
['blosc>=1.10.6,<2.0.0',
 'colorlog>=6.7.0,<7.0.0',
 'minio>=7.1.0,<8.0.0',
 'numpy>=1.21.0,<2.0.0',
 'passlib>=1.7.4,<2.0.0',
 'psycopg2-binary>=2.9.1,<3.0.0',
 'python-dotenv>=0.18.0,<0.19.0',
 'tqdm>=4.61.2,<5.0.0']

entry_points = \
{'console_scripts': ['pymq-init = pymedquery.mqInit:run_setup']}

setup_kwargs = {
    'name': 'pymedquery',
    'version': '2.12.1b0',
    'description': 'This is a python client for the medical-database MedQuery',
    'long_description': '# pyMedQuery [<img align="right" width="120" alt="20200907_104224" src="https://user-images.githubusercontent.com/29639563/183247351-53e45de2-09cf-4344-be30-120d8a744d5f.png">](https://neomedsys.io/)\n\n[![py-medquery](https://github.com/CRAI-OUS/py-medquery/actions/workflows/pymedquery.yaml/badge.svg)](https://github.com/CRAI-OUS/py-medquery/actions/workflows/pymedquery.yaml) <img src="./pymedquery/docs/coverage.svg"> [![Python 3.9](https://img.shields.io/badge/python-3.9-blue.svg)](https://www.python.org/downloads/release/python-390/)\n[![Python 3.8](https://img.shields.io/badge/python-3.8-blue.svg)](https://www.python.org/downloads/release/python-380/)\n[![PyPI status](https://img.shields.io/pypi/status/ansicolortags.svg)](https://pypi.python.org/pypi/ansicolortags/)\n\n<br>\n\n*pyMedQuery* is the sweet sweet database client for python that allows authenticated users to access medical data in the database MedQuery. The main reason for *pyMedQuery* to exist is to efficiently enable database access via python code that can be integrated into machine learning projects, production systems and data analysis pipelines. We are using SSL/TLS for safe connections and client certifications for authentication in order to keep the database connection highly secure. \n\nThe average user is expected to instantiate the `PyMedQuery()` class and run the methods `extract` or `batch_extract` to extract the necessary data for their given project. If the user wants to use the default SQL script then set the argument `get_all` to true in the `(batch_)extract` method and specify which projectID the data should relate to. The method will then extract all the data belonging to that projectID. Other users might find it usefull to write custom SQL scripts where the argument `format_params` can be passed into the extraction for flexible formating of SQL queries. This is especially useful for applications and pipelines.\n\nIf you have any feedback or ideas to new features or bugs then please get in contact with us.\n\n*pyMedQuery* is meant to be a simple and friendly. We hope you\'ll like it! Check out the tutorial script for some examples. \n\n### Quickstart Guide\n\n#### 1. installing and completing the settings (this is a one time procedure)\n\n1. Use poetry or any other kind of dependency manager to install the package.\n\n```$ poetry add pymedquery```\n\n2. If you are using poetry then run `poetry run pymq-init` and follow the setup of the database authentication. (A valid username, password and cert files are currently required in forehand) The setup script will guide you through the authentication. A more streamlined way to authenticate via a MedQuery\'s CLI is in the roadmap for 2022.\n\n<details>\n<summary>Open this drop down if you want to do the authentication manually or you are on Windows with no bash in power shell:</summary>\n<br>\n\n2. Store the certification and key files for postgres somwhere safe on your machine. (you will receive the database credentials from the admins)\n\n3. Set environment variables on your system for the file paths that point to the cert and key files you received for the database. We recommended to put the commands in your .zshrc or .bashrc.\n\n```\n$ echo \'export PGSSLCERT=file_path_to_client_crt\' >> ~/<.your_rc_file>\n$ echo \'export PGSSLROOTCERT=file_path_to_ca_crt\' >> ~/<.your_rc_file>\n$ echo \'export PGSSLKEY=file_path_to_client_key\' >> ~/<.your_rc_file>\n```\n\nSet correct permissions on your client key in order for the database to read it.\n```\n$ chmod 600 $PGSSLKEY\n```\n\nDo the equivalent on windows with\n\n```\nsetx PGSSLCERT file_path_to_client_crt\nsetx PPGSSLROOTCERT file_path_to_ca_crt\nsetx PGSSLKEY file_path_to_client_key\n```\n\n<details>\n<summary>Windows is not a straight forward when setting 600 permission but you can follow these steps:</summary>\n<br>\n\n- Right-click on the target file and select properties then select Security Tab\n\n- Click Advanced and then make sure inheritance is disabled.\n\n- Click apply and then click Edit in the security menu\n\n- Remove all users except Admin user, which should have full control *Admin account should have all checkboxes checked on Allow column except special permission.\n\n- Click Apply and then click OK :)\n        \n<br>\n</details>\n\n\n4. Also include the username and password in your rc file as environment variables:\n\n```\n<your-rc-file>\n# (env vars to fill out that pyMedQuery will pick up on)\nexport MQUSER=\'username-to-medquery\'\nexport MQPWD=\'password-to-medquery\'\nexport DATABASE=\'medquery\'\n```\n##### NOTE! The env var names is a strict convention. The program will not work if you use other names.\n\n<br>\n</details>\n\n#### 2. Examples of how to run the basics\n\n0.  Extracting a small data sample by using the default SQL script and a certain `project_id`. Given that `get_all` is true then you can adjust\n        how many patients to include in your query by filling in limit. If you leave it blank then the query will retrieve all records in the\n        `project_id`. If the data has corresponding masks, then set `include_mask` to true\n\n```python\nfrom pymedquery import pymq\n        \n# instantiate the class\nmq = pymq.PyMedQuery()\n# Use the limit argument to set a maximum number of patients to include in the extraction\nsmall_data_sample = mq.extract(get_all=True, get_affines=True, project_id=\'fancyID\', limit=200, include_mask=False)\n        # do more stuff here\n        # save processed data to your local disk with e.g. in HDF5 or pickle. Let go of big cluttering file systems!\n```\n\n\n1.  Extracting a small data sample with a custom and formatable SQL script where data has corresponding masks.\n        A mask in this case is a finished image segmentation.\n\n```python\nfrom pymedquery import pymq\nfrom config import config\n\nsql_file_path =  # file-path-to-the-pre-written-sql-script\n# instantiate the class\nmq = pymq.PyMedQuery()\n        \n# The formatable parameters will be inserted into the custom SQL scrip and thus extracting data belonging to\n# \'fancy_id\' from only the year 2012 and for only women between 40 and 49. The SQL script must include the\n# format syntax {project_id}, {start_time}..., etc. for the filtering to happen.\nFORMAT_PARAMS = {\n        \'project_id\': \'fancy_id\',\n        \'start_time\': \'2012-01-01\',\n        \'end_time\': \'2012-12-31\',\n        \'gender\': \'F\',\n        \'age_group\': \'40-49\'\n        }\n        \n# Note that the SQL file path is given by a configuartion script called config\n# Lets set get_affines to False in order to include the affine matrices as well\nsmall_data_sample = mq.extract(get_all=False, get_affines=False, format_params=FORMAT_PARAMS, sql_file_path=config.SQL_FILE_PATH, include_mask=True)\n        # do more stuff\n        # save processed data to local disk with e.g. in HDF5 orpickle\n```\n        \n2. Extracting large amounts of data (this step could either be done with a custom SQL file or without. The example is given with the default SQL file for brevity.\n\n```python\nfrom pymedquery import pymq\n\n# instantiate the class\nmq = pymq.PyMedQuery()\n\n# Setting batch size to 200 volumes with 150 slices each. That corresponds to 30000 2D images in each batch\nlarge_data = mq.batch_extract(get_all=True, project_id=\'fancyID\', batch_size=200)\nfor batch in large_data:\n        # do more stuff here:\n        # 1. process data\n        # 2. split train, test and val\n        # 3. save processed data to your local disk with e.g. HDF5\n```\n##### NOTE: it\'s advisable to save your processed data in a HDF5 file as it\'s easy to structure your data in the file and it can be lazy loaded into other scripts for subsequent analyses.\n        \n3. Uploading data into MedQuery. You can either create your own table in a specific part of MedQuery or use a pre-existing table (there will be tables for the data and model versioning and storing)\n\n```python\nfrom pymedquery import pymq\n\n# instantiate the class\nmq = mq.PyMedQuery()\n \n# load the model file into the program\nmodel_file = load_model()\n\n# We are done with a model and I we want to save it back to MedQuery with the proper version for other researchers and applications to use.\n# Befor we make the upload, we need to have dictionary containing the records to upload. The dictionary keys must align with sorting of the table coulumns. Make sure that this is correct befor uploading. Use the \'verbose\' argument if you want to make sure that you structure is correct.\n# the structure of the records dict should be: {key: (record_value, blob),....}\nrecords Dict[str, Tuple[Any, Any]: = {\n        # record_value: blob (not all record_values have a corresponding blob)\n        \'timestamp\': (datetime.datetime.now(), None),\n        \'model_id\': (\'model_fasde32r345t45c324xd\', model_file),\n        \'model_version\': (\'modelw_v1.1.0\', None),\n        \'project_owner\': (\'Schlomo Cohen\': None)\n        }\n\n \n# Upload the records with pymedquery\nmq.upload(records=records, table_name=\'model_artifacts\', verbose=True, image_extraction=False)\n          \n# NOTE! Blobs for record_values are not supported at the moment\n```\n\n##### The records dict aligns with the `model_artifacts` table which has the following columns:\n        \n      | time | model_id | model_version | project_owner |\n\n##### The project pyMedQuery is currently in Beta and we are looking for Beta tester. You have to be affiliated or employed at UHO to take part in the Beta release\n',
    'author': 'Jon E Nesvold',
    'author_email': 'jon.nesvold@pm.me',
    'maintainer': None,
    'maintainer_email': None,
    'url': None,
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.8,<4.0',
}


setup(**setup_kwargs)
