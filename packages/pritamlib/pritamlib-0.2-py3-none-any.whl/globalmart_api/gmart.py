import pandas as pd, requests, os
from urllib.parse import urljoin
from math import isnan

class API:
    def __init__(self, base_url=None, header=None, *endpoints):
        self.base_url = base_url
        self.endpoints = endpoints
        self.header = header

    def show_urls(self):
        print(f"base url of API is: {self.base_url}", "endpoints are:", sep="\n\n")
        [print(ep) for ep in self.endpoints]

    def write_to_csv(self, df, path_to_csv):
        df.to_csv(path_to_csv)


class globalmartAPI(API):
    def __init__(self, base_url=None, header=None, *endpoints):
        super().__init__(base_url, header, *endpoints)

    def getrecords(self, endpoint, qparam, no_of_records=100):
        no_of_loops = int(no_of_records/100)
        extra_limit = no_of_records - no_of_loops*100
        records = []
        response = requests.get(urljoin(self.base_url, endpoint), headers=self.header, params=qparam)
        if(response.status_code != 200):
            return records
        else:
            records += response.json()["data"]
        for _ in range(no_of_loops-1):
            response = requests.get(urljoin(self.base_url, response.json()["next"]), headers=self.header)
            if(response.status_code != 200):
                return records
            else:
                records += response.json()["data"]
        qparam["offset"], qparam["limit"] = no_of_loops*100+1, extra_limit
        records += requests.get(urljoin(self.base_url, endpoint), headers=self.header, params=qparam).json()["data"]
        return records

    def jsonToDataframe(self, json_inp):
        '''
        Returns the sum of two decimal numbers in binary digits.

                Parameters:
                        json_inp (python dict): response of the API in form of json

                Returns:
                        df (Pandas dataframe): This is the dataframe that got generated by parsing the json
                        response from the API
        '''
        df = pd.json_normalize(json_inp)
        cleaned_column_names = [x if(len(x.split('.')) == 1) else x.split('.')[-1] for x in df.columns]
        df.columns = cleaned_column_names
        return df

    
class Order:
    all_orders = []
    def __init__(self, order_id, df) -> None:
        self.order_id = order_id
        self.df = df
        Order.all_orders.append(order_id)

    def calculate_total(self):
        return self.df[self.df["order_id"] == self.order_id]["sales_amt"].sum().round(2)
    
    @classmethod
    def showorders(cls):
        [print(x) for x in cls.all_orders]


class Order_discount(Order):
    def __init__(self, order_id, df) -> None:
        super().__init__(order_id, df)

    def calculate_total(self):
        self.df = self.df.assign(
            sales_amt_updated = lambda x: x["sales_amt"]*(1-x["discount"])
        )
        filtered_df = self.df[self.df["order_id"] == self.order_id]
        return filtered_df["sales_amt_updated"].sum().round(2)


def no_of_orders_state(df, state):
    df_cleaned = df.assign(
        cleaned_state = df["state"].str.strip()
    )
    return df_cleaned[df_cleaned["cleaned_state"].str.contains('california|calfornia', case=False)]["order_id"].nunique()

def avg_purchase_freq(df, state):
    df_state = df[df["state"] == state][["order_id", "order_purchase_date"]].sort_values("order_purchase_date")
    df_state = df_state.assign(
        next_order_purchase_date = lambda x: x["order_purchase_date"].shift(periods=-1)
    )
    df_state = df_state.assign(
        days_1 = lambda x: round((x["next_order_purchase_date"]-x["order_purchase_date"])/pd.Timedelta(days=1), 2),
    )
    df_state = df_state.groupby(["order_id", "order_purchase_date"], as_index=False)["days_1"].max()
    return round(df_state["days_1"].mean(), 2)


